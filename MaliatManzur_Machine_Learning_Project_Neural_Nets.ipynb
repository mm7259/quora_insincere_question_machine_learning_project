{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Activation, Conv1D, MaxPooling1D, Flatten, BatchNormalization\n",
    "from gensim.models import KeyedVectors\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the data \n",
    "column_names = ['qid', 'question_text', 'target']\n",
    "df = pd.read_csv('./train.csv', names=column_names, header=None, na_values='?', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_embeddings = \"./GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin\"\n",
    "embeddings_index = KeyedVectors.load_word2vec_format(path_to_embeddings, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array(df['target'][1:2001])\n",
    "X = np.array(df['question_text'][1:2001])\n",
    "\n",
    "X_words, X_test_words, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500,)\n",
      "(500,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1306123, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(6)\n",
    "print(X_words.shape)\n",
    "print(X_test_words.shape)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_matrix(resulting_array, max_row_length): \n",
    "    if resulting_array.size == 0: \n",
    "        resulting_array = np.reshape(resulting_array, (0, max_row_length))\n",
    "    else: \n",
    "        diff = max_row_length - resulting_array.shape[1]\n",
    "        if diff % 2 == 1: \n",
    "            left = diff // 2 + 1 \n",
    "        else: \n",
    "            left = diff // 2 \n",
    "        right = diff // 2 \n",
    "        \n",
    "        resulting_array = np.pad(resulting_array, ((0,0),(left,right)), 'constant', constant_values=(0,0))\n",
    "    return resulting_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_row_length(array, max_row_length):\n",
    "    if len(array.shape) < 2:\n",
    "        array_len = array.shape[0] #array has to be a numpy array\n",
    "    else: \n",
    "        array_len = array.shape[1] #array has to be a numpy array\n",
    "    \n",
    "    \n",
    "    if array_len < max_row_length: \n",
    "        diff = max_row_length - array_len\n",
    "        if diff % 2 == 1: \n",
    "            left = diff // 2 + 1 \n",
    "        else: \n",
    "            left = diff // 2 \n",
    "        right = diff // 2 \n",
    "        if len(array.shape) < 2:\n",
    "            array = np.pad(array, (left,right), 'constant', constant_values=(0,0))\n",
    "        else:\n",
    "            array = np.pad(array, ((0,0),(left,right)), 'constant', constant_values=(0,0))\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the embeddings\n",
    "# create a vector with the embeddings values \n",
    "# put all the embeddings together to create a row in the matrix \n",
    "# check if the lenghth of the concatenated embeddings array is bigger than the current length of each row in np.array\n",
    "# if it's shorter, pass it on to the fix_length function\n",
    "\n",
    "def vectorize_questions(words):\n",
    "    max_row_length = 0\n",
    "    resulting_array = np.array([])\n",
    "\n",
    "    for sentence in words: \n",
    "        stripped_sentence = sentence.replace(\"?\", \"\")\n",
    "        words = stripped_sentence.split()\n",
    "        sentence_vector = []\n",
    "        for word in words: \n",
    "            if word in embeddings_index: \n",
    "                sentence_vector.extend(embeddings_index[word])\n",
    "\n",
    "        #turn it into a np_array\n",
    "        sentence_vector = np.array(sentence_vector)\n",
    "        sentence_vector = np.reshape(sentence_vector, (1, sentence_vector.shape[0]))\n",
    "\n",
    "        if sentence_vector.shape[1] > max_row_length: \n",
    "            max_row_length = sentence_vector.shape[1]\n",
    "            resulting_array = fix_matrix(resulting_array, max_row_length)\n",
    "        elif sentence_vector.shape[1] < max_row_length:     \n",
    "            sentence_vector=fix_row_length(sentence_vector, max_row_length)\n",
    "\n",
    "        resulting_array = np.append(resulting_array, sentence_vector, axis=0)\n",
    "    return resulting_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-process training set and test set\n",
    "X_train = vectorize_questions(X_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vectorize_questions(X_test_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 13200)\n",
      "(500, 11400)\n",
      "(1500, 13200)\n",
      "(500, 13200)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "#fix shape difference\n",
    "\n",
    "diff = abs(X_train.shape[1] - X_test.shape[1])\n",
    "if diff % 2 == 1: \n",
    "    left = diff // 2 + 1 \n",
    "else: \n",
    "    left = diff // 2 \n",
    "right = diff // 2 \n",
    "\n",
    "if (X_train.shape < X_test.shape): \n",
    "    X_train = np.pad(X_train, ((0,0),(left,right)), 'constant', constant_values=(0,0))\n",
    "else:\n",
    "    X_test = np.pad(X_test, ((0,0),(left,right)), 'constant', constant_values=(0,0))\n",
    "    \n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K \n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hiden (Dense)                (None, 100)               1320100   \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 1,320,302\n",
      "Trainable params: 1,320,302\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = X_train.shape\n",
    "nin = X_train.shape[1]\n",
    "nh = 100\n",
    "nout = 2\n",
    "model = Sequential()\n",
    "# model.add(Conv1D(32, kernel_size=(3,), strides=(1, ), activation='relu', input_shape=input_shape))\n",
    "# model.add(MaxPooling1D(pool_size=(2, ), strides=(2, )))\n",
    "# model.add(Conv1D(64, (3,), activation='relu'))\n",
    "# model.add(MaxPooling1D(pool_size=(2, )))\n",
    "# model.add(Conv1D(64, (3,), activation='relu'))\n",
    "# model.add(Conv1D(64, (4,), activation='relu'))\n",
    "# model.add(MaxPooling1D(pool_size=(2, )))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(2000, activation='relu'))\n",
    "# model.add(Dense(1000, activation='relu'))\n",
    "# model.add(Dense(500, activation='relu'))\n",
    "# # model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(nh, input_shape=(nin,), activation='sigmoid', name='hiden'))\n",
    "model.add(Dense(nout, activation='softmax', name='output'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "opt = optimizers.Adam(lr=0.001) # x_1=0.9, x_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer=opt,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1500 samples, validate on 500 samples\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.2826 - acc: 0.9360 - val_loss: 0.2176 - val_acc: 0.9420\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.1715 - acc: 0.9440 - val_loss: 0.2100 - val_acc: 0.9400\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.1277 - acc: 0.9600 - val_loss: 0.2037 - val_acc: 0.9420\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 0.0980 - acc: 0.9647 - val_loss: 0.2075 - val_acc: 0.9420\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 0.0764 - acc: 0.9753 - val_loss: 0.2081 - val_acc: 0.9400\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 0s 104us/step - loss: 0.0617 - acc: 0.9813 - val_loss: 0.2108 - val_acc: 0.9420\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.0487 - acc: 0.9873 - val_loss: 0.2197 - val_acc: 0.9400\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 0s 106us/step - loss: 0.0389 - acc: 0.9900 - val_loss: 0.2247 - val_acc: 0.9400\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.0317 - acc: 0.9927 - val_loss: 0.2256 - val_acc: 0.9380\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.0254 - acc: 0.9980 - val_loss: 0.2391 - val_acc: 0.9380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b1cee6b45c0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=10, batch_size=100, validation_data=(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.938000\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"accuracy = %f\" % acc)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
