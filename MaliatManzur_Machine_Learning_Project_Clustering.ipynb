{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.cluster import KMeans \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the data \n",
    "column_names = ['qid', 'question_text', 'target']\n",
    "df = pd.read_csv('./train.csv', names=column_names, header=None, na_values='?', low_memory=False)\n",
    "\n",
    "path_to_embeddings = \"./GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin\"\n",
    "embeddings_index = KeyedVectors.load_word2vec_format(path_to_embeddings, binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Y = np.array(df['target'][1:5001])\n",
    "X = np.array(df['question_text'][1:5001])\n",
    "\n",
    "X_words, X_test_words, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_matrix(resulting_array, max_row_length): \n",
    "    if resulting_array.size == 0: \n",
    "        resulting_array = np.reshape(resulting_array, (0, max_row_length))\n",
    "    else: \n",
    "        diff = max_row_length - resulting_array.shape[1]\n",
    "        if diff % 2 == 1: \n",
    "            left = diff // 2 + 1 \n",
    "        else: \n",
    "            left = diff // 2 \n",
    "        right = diff // 2 \n",
    "        \n",
    "        resulting_array = np.pad(resulting_array, ((0,0),(left,right)), 'constant', constant_values=(0,0))\n",
    "    return resulting_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_row_length(array, max_row_length):\n",
    "    if len(array.shape) < 2:\n",
    "        array_len = array.shape[0] #array has to be a numpy array\n",
    "    else: \n",
    "        array_len = array.shape[1] #array has to be a numpy array\n",
    "    \n",
    "    \n",
    "    if array_len < max_row_length: \n",
    "        diff = max_row_length - array_len\n",
    "        if diff % 2 == 1: \n",
    "            left = diff // 2 + 1 \n",
    "        else: \n",
    "            left = diff // 2 \n",
    "        right = diff // 2 \n",
    "        if len(array.shape) < 2:\n",
    "            array = np.pad(array, (left,right), 'constant', constant_values=(0,0))\n",
    "        else:\n",
    "            array = np.pad(array, ((0,0),(left,right)), 'constant', constant_values=(0,0))\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the embeddings\n",
    "# create a vector with the embeddings values \n",
    "# put all the embeddings together to create a row in the matrix \n",
    "# check if the lenghth of the concatenated embeddings array is bigger than the current length of each row in np.array\n",
    "# if it's shorter, pass it on to the fix_length function\n",
    "\n",
    "def vectorize_questions(words):\n",
    "    max_row_length = 0\n",
    "    resulting_array = np.array([])\n",
    "\n",
    "    for sentence in words: \n",
    "        stripped_sentence = sentence.replace(\"?\", \"\")\n",
    "        words = stripped_sentence.split()\n",
    "        sentence_vector = []\n",
    "        for word in words: \n",
    "            if word in embeddings_index: \n",
    "                sentence_vector.extend(embeddings_index[word])\n",
    "\n",
    "        #turn it into a np_array\n",
    "        sentence_vector = np.array(sentence_vector)\n",
    "        sentence_vector = np.reshape(sentence_vector, (1, sentence_vector.shape[0]))\n",
    "\n",
    "        if sentence_vector.shape[1] > max_row_length: \n",
    "            max_row_length = sentence_vector.shape[1]\n",
    "            resulting_array = fix_matrix(resulting_array, max_row_length)\n",
    "        elif sentence_vector.shape[1] < max_row_length:     \n",
    "            sentence_vector=fix_row_length(sentence_vector, max_row_length)\n",
    "\n",
    "        resulting_array = np.append(resulting_array, sentence_vector, axis=0)\n",
    "    return resulting_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3750, 13200)\n",
      "(1250, 11700)\n",
      "(3750, 13200)\n",
      "(1250, 13200)\n"
     ]
    }
   ],
   "source": [
    "#Pre-process training set and test set\n",
    "X_train = vectorize_questions(X_words)\n",
    "X_test = vectorize_questions(X_test_words)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "#fix shape difference\n",
    "\n",
    "diff = abs(X_train.shape[1] - X_test.shape[1])\n",
    "if diff % 2 == 1: \n",
    "    left = diff // 2 + 1 \n",
    "else: \n",
    "    left = diff // 2 \n",
    "right = diff // 2 \n",
    "\n",
    "if (X_train.shape < X_test.shape): \n",
    "    X_train = np.pad(X_train, ((0,0),(left,right)), 'constant', constant_values=(0,0))\n",
    "else:\n",
    "    X_test = np.pad(X_test, ((0,0),(left,right)), 'constant', constant_values=(0,0))\n",
    "    \n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 2\n",
    "kmeans_model = KMeans(n_clusters=n_clusters, n_init=100)\n",
    "yhat = kmeans_model.fit_predict(X_train)\n",
    "# metrics.accuracy_score(Y_train, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.mean(np.equal(yhat, Y_train).astype(int))\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
