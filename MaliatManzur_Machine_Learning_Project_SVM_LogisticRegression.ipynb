{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the data \n",
    "column_names = ['qid', 'question_text', 'target']\n",
    "df = pd.read_csv('./train.csv', names=column_names, header=None, na_values='?', low_memory=False)\n",
    "\n",
    "path_to_embeddings = \"./GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin\"\n",
    "embeddings_index = KeyedVectors.load_word2vec_format(path_to_embeddings, binary=True)\n",
    "\n",
    "Y = np.array(df['target'][1:2001])\n",
    "X = np.array(df['question_text'][1:2001])\n",
    "\n",
    "X_words, X_test_words, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qid</td>\n",
       "      <td>question_text</td>\n",
       "      <td>target</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0                   qid                                      question_text   \n",
       "1  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "2  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "3  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "4  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "5  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "   target  \n",
       "0  target  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "5       0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_matrix(resulting_array, max_row_length): \n",
    "    if resulting_array.size == 0: \n",
    "        resulting_array = np.reshape(resulting_array, (0, max_row_length))\n",
    "    else: \n",
    "        diff = max_row_length - resulting_array.shape[1]\n",
    "        if diff % 2 == 1: \n",
    "            left = diff // 2 + 1 \n",
    "        else: \n",
    "            left = diff // 2 \n",
    "        right = diff // 2 \n",
    "        \n",
    "        resulting_array = np.pad(resulting_array, ((0,0),(left,right)), 'constant', constant_values=(0,0))\n",
    "    return resulting_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_row_length(array, max_row_length):\n",
    "    if len(array.shape) < 2:\n",
    "        array_len = array.shape[0] #array has to be a numpy array\n",
    "    else: \n",
    "        array_len = array.shape[1] #array has to be a numpy array\n",
    "    \n",
    "    \n",
    "    if array_len < max_row_length: \n",
    "        diff = max_row_length - array_len\n",
    "        if diff % 2 == 1: \n",
    "            left = diff // 2 + 1 \n",
    "        else: \n",
    "            left = diff // 2 \n",
    "        right = diff // 2 \n",
    "        if len(array.shape) < 2:\n",
    "            array = np.pad(array, (left,right), 'constant', constant_values=(0,0))\n",
    "        else:\n",
    "            array = np.pad(array, ((0,0),(left,right)), 'constant', constant_values=(0,0))\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the embeddings\n",
    "# create a vector with the embeddings values \n",
    "# put all the embeddings together to create a row in the matrix \n",
    "# check if the lenghth of the concatenated embeddings array is bigger than the current length of each row in np.array\n",
    "# if it's shorter, pass it on to the fix_length function\n",
    "\n",
    "def vectorize_questions(words):\n",
    "    max_row_length = 0\n",
    "    resulting_array = np.array([])\n",
    "\n",
    "    for sentence in words: \n",
    "        stripped_sentence = sentence.replace(\"?\", \"\")\n",
    "        words = stripped_sentence.split()\n",
    "        sentence_vector = []\n",
    "        for word in words: \n",
    "            if word in embeddings_index: \n",
    "                sentence_vector.extend(embeddings_index[word])\n",
    "\n",
    "        #turn it into a np_array\n",
    "        sentence_vector = np.array(sentence_vector)\n",
    "        sentence_vector = np.reshape(sentence_vector, (1, sentence_vector.shape[0]))\n",
    "\n",
    "        if sentence_vector.shape[1] > max_row_length: \n",
    "            max_row_length = sentence_vector.shape[1]\n",
    "            resulting_array = fix_matrix(resulting_array, max_row_length)\n",
    "        elif sentence_vector.shape[1] < max_row_length:     \n",
    "            sentence_vector=fix_row_length(sentence_vector, max_row_length)\n",
    "\n",
    "        resulting_array = np.append(resulting_array, sentence_vector, axis=0)\n",
    "    return resulting_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 13200)\n",
      "(500, 11400)\n",
      "(1500, 13200)\n",
      "(500, 13200)\n"
     ]
    }
   ],
   "source": [
    "#Pre-process training set and test set\n",
    "X_train = vectorize_questions(X_words)\n",
    "X_test = vectorize_questions(X_test_words)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "#fix shape difference\n",
    "\n",
    "diff = abs(X_train.shape[1] - X_test.shape[1])\n",
    "if diff % 2 == 1: \n",
    "    left = diff // 2 + 1 \n",
    "else: \n",
    "    left = diff // 2 \n",
    "right = diff // 2 \n",
    "\n",
    "if (X_train.shape < X_test.shape): \n",
    "    X_train = np.pad(X_train, ((0,0),(left,right)), 'constant', constant_values=(0,0))\n",
    "else:\n",
    "    X_test = np.pad(X_test, ((0,0),(left,right)), 'constant', constant_values=(0,0))\n",
    "    \n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mm7259/jupyter_install/py3.6.3_gpu/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l1', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = linear_model.LogisticRegression(C=.001, penalty='l1')\n",
    "logreg.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.942\n"
     ]
    }
   ],
   "source": [
    "yhat =  logreg.predict(X_test)\n",
    "accuracy = np.mean(np.equal(yhat, Y_test).astype(int))\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "svc = svm.SVC(probability=False,  kernel=\"rbf\", C=2.8, gamma=.0073,verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=2.8, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.0073, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuaracy = 0.942000\n"
     ]
    }
   ],
   "source": [
    "yhat_svm = svc.predict(X_test)\n",
    "acc = np.mean(np.equal(yhat_svm, Y_test).astype(int))\n",
    "print('Accuaracy = {0:f}'.format(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
